{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - with missing indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"data/test.csv\", index_col=0)  # does not contain targets\n",
    "\n",
    "#Gender\n",
    "train_no_gender = train.copy().drop(columns=\"Gender\")\n",
    "test_no_gedner = test.copy().drop(columns=\"Gender\")\n",
    "\n",
    "# Married\n",
    "train_no_nan_married = train_no_gender.copy().dropna(axis=0, subset=[\"Married\"])\n",
    "train_no_nan_married = pd.get_dummies(train_no_nan_married, columns=[\"Married\"], drop_first=True)\n",
    "\n",
    "# Dependents\n",
    "train_dependent_only_int = train_no_nan_married.copy().replace(\"3+\", 3)\n",
    "for number in range(0, 3):\n",
    "    train_dependent_only_int = train_dependent_only_int.replace(f\"{number}\", number)\n",
    "\n",
    "train_dependents_no_nan = train_dependent_only_int.copy()\n",
    "median = np.nanmedian(train_dependent_only_int.Dependents)\n",
    "train_dependents_no_nan[\"Missing_Dependents\"] = [int(x) for x in train_dependent_only_int.Dependents.isnull().values]\n",
    "train_dependents_no_nan.Dependents = train_dependent_only_int.copy().Dependents.fillna(median)\n",
    "\n",
    "# Education\n",
    "train_education_dummies = pd.get_dummies(train_dependents_no_nan.copy(), columns=[\"Education\"], drop_first=True)\n",
    "\n",
    "missing_ind = MissingIndicator(error_on_new=True, features=\"missing-only\")\n",
    "train_self_employed_encoded = train_education_dummies.copy()\n",
    "\n",
    "# Self_Employed\n",
    "train_self_employed_encoded[\"Missing_Self_Employed\"] = missing_ind.fit_transform(train_self_employed_encoded.Self_Employed.values.reshape(-1, 1))\n",
    "train_self_employed_encoded[\"Missing_Self_Employed\"] = train_self_employed_encoded[\"Missing_Self_Employed\"].replace([True, False], [1, 0])\n",
    "train_self_employed_encoded.Self_Employed = train_self_employed_encoded.Self_Employed.replace([np.nan, \"No\", \"Yes\"], [0, 0, 1]) \n",
    "\n",
    "# Loan_Amount_Term\n",
    "si = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_imputed_loan_amount_term = train_self_employed_encoded.copy()\n",
    "train_imputed_loan_amount_term.Loan_Amount_Term = si.fit_transform(train_imputed_loan_amount_term.Loan_Amount_Term.values.reshape(-1, 1))\n",
    "\n",
    "# Credit_History\n",
    "train_credit_history_no_nan = train_imputed_loan_amount_term.copy()\n",
    "\n",
    "missing_ind = MissingIndicator(error_on_new=True, features=\"missing-only\")\n",
    "si = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_credit_history_no_nan[\"Missing_Credit_History\"] = missing_ind.fit_transform(train_credit_history_no_nan.Credit_History.values.reshape(-1, 1))\n",
    "train_credit_history_no_nan[\"Missing_Credit_History\"] = train_credit_history_no_nan[\"Missing_Credit_History\"].replace([True, False], [1, 0])\n",
    "\n",
    "train_credit_history_no_nan.Credit_History = si.fit_transform(train_credit_history_no_nan.Credit_History.values.reshape(-1, 1))\n",
    "\n",
    "# Property_Area and Loan_Status\n",
    "train_property_area_n_target = pd.get_dummies(train_credit_history_no_nan.copy(), columns=[\"Property_Area\", \"Loan_Status\"], drop_first=True)\n",
    "\n",
    "# Loan amount\n",
    "train_LoanAmount_itterative_imputer = train_property_area_n_target.copy()\n",
    "\n",
    "X = train_LoanAmount_itterative_imputer.iloc[:, :-1]\n",
    "y = train_LoanAmount_itterative_imputer.iloc[:, -1]\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=0)\n",
    "X = imp_mean.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X, columns=train_LoanAmount_itterative_imputer.iloc[:, :-1].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - containing nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"data/test.csv\", index_col=0)  # does not contain targets\n",
    "\n",
    "#Gender\n",
    "train_no_gender = train.copy().drop(columns=\"Gender\")\n",
    "test_no_gedner = test.copy().drop(columns=\"Gender\")\n",
    "\n",
    "# Married\n",
    "train_no_nan_married = train_no_gender.copy().dropna(axis=0, subset=[\"Married\"])\n",
    "train_no_nan_married = pd.get_dummies(train_no_nan_married, columns=[\"Married\"], drop_first=True)\n",
    "\n",
    "# Dependents\n",
    "train_dependent_only_int = train_no_nan_married.copy().replace(\"3+\", 3)\n",
    "for number in range(0, 3):\n",
    "    train_dependent_only_int = train_dependent_only_int.replace(f\"{number}\", number)\n",
    "\n",
    "train_dependents_no_nan = train_dependent_only_int.copy()\n",
    "#median = np.nanmedian(train_dependent_only_int.Dependents)\n",
    "#train_dependents_no_nan[\"Missing_Dependents\"] = [int(x) for x in train_dependent_only_int.Dependents.isnull().values]\n",
    "#train_dependents_no_nan.Dependents = train_dependent_only_int.copy().Dependents.fillna(median)\n",
    "\n",
    "# Education\n",
    "train_education_dummies = pd.get_dummies(train_dependents_no_nan.copy(), columns=[\"Education\"], drop_first=True)\n",
    "\n",
    "#missing_ind = MissingIndicator(error_on_new=True, features=\"missing-only\")\n",
    "train_self_employed_encoded = train_education_dummies.copy()\n",
    "\n",
    "# Self_Employed\n",
    "#train_self_employed_encoded[\"Missing_Self_Employed\"] = missing_ind.fit_transform(train_self_employed_encoded.Self_Employed.values.reshape(-1, 1))\n",
    "#train_self_employed_encoded[\"Missing_Self_Employed\"] = train_self_employed_encoded[\"Missing_Self_Employed\"].replace([True, False], [1, 0])\n",
    "train_self_employed_encoded.Self_Employed = train_self_employed_encoded.Self_Employed.replace([\"No\", \"Yes\"], [0, 1]) \n",
    "\n",
    "# Loan_Amount_Term\n",
    "si = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_imputed_loan_amount_term = train_self_employed_encoded.copy()\n",
    "train_imputed_loan_amount_term.Loan_Amount_Term = si.fit_transform(train_imputed_loan_amount_term.Loan_Amount_Term.values.reshape(-1, 1))\n",
    "\n",
    "# Credit_History\n",
    "##train_credit_history_no_nan = train_imputed_loan_amount_term.copy()\n",
    "\n",
    "##missing_ind = MissingIndicator(error_on_new=True, features=\"missing-only\")\n",
    "##si = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "##train_credit_history_no_nan[\"Missing_Credit_History\"] = missing_ind.fit_transform(train_credit_history_no_nan.Credit_History.values.reshape(-1, 1))\n",
    "##train_credit_history_no_nan[\"Missing_Credit_History\"] = train_credit_history_no_nan[\"Missing_Credit_History\"].replace([True, False], [1, 0])\n",
    "\n",
    "##train_credit_history_no_nan.Credit_History = si.fit_transform(train_credit_history_no_nan.Credit_History.values.reshape(-1, 1))\n",
    "\n",
    "# Property_Area and Loan_Status\n",
    "train_property_area_n_target = pd.get_dummies(train_imputed_loan_amount_term.copy(), columns=[\"Property_Area\", \"Loan_Status\"], drop_first=True)\n",
    "\n",
    "# Loan amount\n",
    "train_LoanAmount_itterative_imputer = train_property_area_n_target.copy()\n",
    "\n",
    "X = train_LoanAmount_itterative_imputer.iloc[:, :-1]\n",
    "y = train_LoanAmount_itterative_imputer.iloc[:, -1]\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=0)\n",
    "X = imp_mean.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X, columns=train_LoanAmount_itterative_imputer.iloc[:, :-1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Missing_Dependents</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>Missing_Self_Employed</th>\n",
       "      <th>Missing_Credit_History</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.028436</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8072.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dependents  Self_Employed  ApplicantIncome  CoapplicantIncome  \\\n",
       "0           0.0            0.0           5849.0                0.0   \n",
       "1           1.0            0.0           4583.0             1508.0   \n",
       "2           0.0            1.0           3000.0                0.0   \n",
       "3           0.0            0.0           2583.0             2358.0   \n",
       "4           0.0            0.0           6000.0                0.0   \n",
       "..          ...            ...              ...                ...   \n",
       "606         0.0            0.0           2900.0                0.0   \n",
       "607         3.0            0.0           4106.0                0.0   \n",
       "608         1.0            0.0           8072.0              240.0   \n",
       "609         2.0            0.0           7583.0                0.0   \n",
       "610         0.0            1.0           4583.0                0.0   \n",
       "\n",
       "     LoanAmount  Loan_Amount_Term  Credit_History  Married_Yes  \\\n",
       "0    138.028436             360.0             1.0          0.0   \n",
       "1    128.000000             360.0             1.0          1.0   \n",
       "2     66.000000             360.0             1.0          1.0   \n",
       "3    120.000000             360.0             1.0          1.0   \n",
       "4    141.000000             360.0             1.0          0.0   \n",
       "..          ...               ...             ...          ...   \n",
       "606   71.000000             360.0             1.0          0.0   \n",
       "607   40.000000             180.0             1.0          1.0   \n",
       "608  253.000000             360.0             1.0          1.0   \n",
       "609  187.000000             360.0             1.0          1.0   \n",
       "610  133.000000             360.0             0.0          0.0   \n",
       "\n",
       "     Missing_Dependents  Education_Not Graduate  Missing_Self_Employed  \\\n",
       "0                   0.0                     0.0                    0.0   \n",
       "1                   0.0                     0.0                    0.0   \n",
       "2                   0.0                     0.0                    0.0   \n",
       "3                   0.0                     1.0                    0.0   \n",
       "4                   0.0                     0.0                    0.0   \n",
       "..                  ...                     ...                    ...   \n",
       "606                 0.0                     0.0                    0.0   \n",
       "607                 0.0                     0.0                    0.0   \n",
       "608                 0.0                     0.0                    0.0   \n",
       "609                 0.0                     0.0                    0.0   \n",
       "610                 0.0                     0.0                    0.0   \n",
       "\n",
       "     Missing_Credit_History  Property_Area_Semiurban  Property_Area_Urban  \n",
       "0                       0.0                      0.0                  1.0  \n",
       "1                       0.0                      0.0                  0.0  \n",
       "2                       0.0                      0.0                  1.0  \n",
       "3                       0.0                      0.0                  1.0  \n",
       "4                       0.0                      0.0                  1.0  \n",
       "..                      ...                      ...                  ...  \n",
       "606                     0.0                      0.0                  0.0  \n",
       "607                     0.0                      0.0                  0.0  \n",
       "608                     0.0                      0.0                  1.0  \n",
       "609                     0.0                      0.0                  1.0  \n",
       "610                     0.0                      1.0                  0.0  \n",
       "\n",
       "[611 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': False,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': 100,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state=100, n_estimators=1000, use_label_encoder=False)\n",
    "\n",
    "xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid   = [\n",
    "    {'learning_rate': [0.1, 0.05, 0.001], \n",
    "     'max_depth': [2,3,4,5,6,7,8,9],\n",
    "     #'logisticregression__penalty': ['l2'],\n",
    "     #'logisticregression__solver': ['newton-cg', 'lbfgs', 'saga', 'sag']\n",
    "    }\n",
    "    ]  # param_grid containing all parameters that I want to change to get the most optimal solution for the SVM algorithm\n",
    "\n",
    "gs = GridSearchCV(estimator  = xgb,\n",
    "                  param_grid = param_grid,\n",
    "                  scoring    = 'accuracy',\n",
    "                  cv         = 5,\n",
    "                  n_jobs     = -1,\n",
    "                  verbose    = 3)  # Searching through all possible combinations from param_grid. Cross-validation with 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gs = gs.fit(X_train, y_train)  # Fit the training data to grid search to find the parameters that gives the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8245417236662107\n",
      "Best params:\n",
      "{'learning_rate': 0.001, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Best score: {gs.best_score_}\")\n",
    "print(f\"Best params:\\n{gs.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637 +/- 0.0407 {'learning_rate': 0.1, 'max_depth': 2}\n",
      "0.7685 +/- 0.0688 {'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.7777 +/- 0.0452 {'learning_rate': 0.1, 'max_depth': 4}\n",
      "0.7801 +/- 0.0522 {'learning_rate': 0.1, 'max_depth': 5}\n",
      "0.7801 +/- 0.0538 {'learning_rate': 0.1, 'max_depth': 6}\n",
      "0.7825 +/- 0.0552 {'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.7848 +/- 0.0559 {'learning_rate': 0.1, 'max_depth': 8}\n",
      "0.7731 +/- 0.0533 {'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.7871 +/- 0.0416 {'learning_rate': 0.05, 'max_depth': 2}\n",
      "0.7895 +/- 0.0622 {'learning_rate': 0.05, 'max_depth': 3}\n",
      "0.7731 +/- 0.0488 {'learning_rate': 0.05, 'max_depth': 4}\n",
      "0.7801 +/- 0.0544 {'learning_rate': 0.05, 'max_depth': 5}\n",
      "0.7661 +/- 0.0599 {'learning_rate': 0.05, 'max_depth': 6}\n",
      "0.7824 +/- 0.0538 {'learning_rate': 0.05, 'max_depth': 7}\n",
      "0.7871 +/- 0.0587 {'learning_rate': 0.05, 'max_depth': 8}\n",
      "0.7731 +/- 0.0528 {'learning_rate': 0.05, 'max_depth': 9}\n",
      "0.8175 +/- 0.0393 {'learning_rate': 0.001, 'max_depth': 2}\n",
      "0.8175 +/- 0.0393 {'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.8175 +/- 0.0393 {'learning_rate': 0.001, 'max_depth': 4}\n",
      "0.8175 +/- 0.0393 {'learning_rate': 0.001, 'max_depth': 5}\n",
      "0.8245 +/- 0.0389 {'learning_rate': 0.001, 'max_depth': 6}\n",
      "0.8175 +/- 0.0329 {'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.8104 +/- 0.0336 {'learning_rate': 0.001, 'max_depth': 8}\n",
      "0.8175 +/- 0.0441 {'learning_rate': 0.001, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "for r, _ in enumerate(gs.cv_results_['mean_test_score']):\n",
    "    print(\"%0.4f +/- %0.4f %r\"\n",
    "          % (gs.cv_results_['mean_test_score'][r],\n",
    "             gs.cv_results_['std_test_score'][r],\n",
    "             gs.cv_results_['params'][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test accuracy: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eirik\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Test accuracy: {clf.score(X_test, y_test):.3f}\")  # Looking at how the model preformed against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
